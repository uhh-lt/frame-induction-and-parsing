{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from src.run_postprocessing_predictions import calculate_true_positives\n",
    "from src.postprocessing import remove_seedword, lemmatize\n",
    "\n",
    "def upperbound_baseline(seed_words, gold_clusters, \n",
    "                        save_results_path,\n",
    "                        test_indexes_path=None,\n",
    "                        k=50,\n",
    "                        seed=42):\n",
    "    \n",
    "    assert len(seed_words) == len(gold_clusters)\n",
    "    random.seed(seed)\n",
    "\n",
    "    \n",
    "    \n",
    "    if test_indexes_path is not None:\n",
    "        df = pd.DataFrame()\n",
    "        df['gold_clusters'] = gold_clusters\n",
    "        df['seed_words'] = seed_words\n",
    "        with open(test_indexes_path, 'r') as f:\n",
    "            test_indexes = json.load(f)\n",
    "            if len(gold_clusters)!= len(test_indexes):\n",
    "                        df = df.loc[test_indexes].copy().reset_index(drop=True)    \n",
    "        seed_words = df['seed_words']\n",
    "        gold_clusters = df['gold_clusters']\n",
    "                \n",
    "    predictions = []\n",
    "    \n",
    "    seed_words = [w.lower() for w in seed_words]\n",
    "#     seed_words = lemmatize(seed_words)\n",
    "    gold_clusters_preds = remove_seedword(seed_words, gold_clusters)\n",
    "    \n",
    "    for w, gd in zip(seed_words, gold_clusters_preds):\n",
    "        \n",
    "        G = len(gd)\n",
    "        if G < k:\n",
    "            preds = random.sample(gd, G)\n",
    "            for i in range(k-G):\n",
    "                preds.append(\"NO\")\n",
    "        else:\n",
    "            preds = random.sample(gd, k)\n",
    "#         print(w)\n",
    "#         print(gd)\n",
    "#         print(preds)    \n",
    "        predictions.append(preds)\n",
    "    \n",
    "    print('Saving final predictions...', len(predictions))\n",
    "    \n",
    "    if not os.path.exists(save_results_path):\n",
    "        os.mkdir(save_results_path)\n",
    "        \n",
    "    with open(os.path.join(save_results_path, 'final_predictions.pkl'), 'wb') as f:\n",
    "        pickle.dump(predictions, f)\n",
    "        \n",
    "    calculate_true_positives(predictions, \n",
    "                         gold_clusters, \n",
    "                         save_dir_path,\n",
    "                         k=k)\n",
    "    \n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-mineral",
   "metadata": {},
   "source": [
    "## Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results_path = \"workdir/upperbound_results/paper_verbs_st2\"\n",
    "test_indexes_path = 'workdir/data/swv_gold_dataset_test_split.json'\n",
    "\n",
    "gold_df = pd.read_pickle(\"workdir/data/swv_gold_dataset.pkl\")\n",
    "\n",
    "\n",
    "final_preds = upperbound_baseline(gold_df['luName'], gold_df['gold_cluster_processed'],\n",
    "                                 save_results_path,\n",
    "                                 test_indexes_path=test_indexes_path,\n",
    "                                 k=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-marine",
   "metadata": {},
   "source": [
    "## Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results_path = \"workdir/upperbound_results/paper_nouns_st\"\n",
    "test_indexes_path = 'workdir/data/swn_gold_dataset_test_split.json'\n",
    "gold_df = pd.read_pickle(\"workdir/data/swn_gold_dataset.pkl\")\n",
    "\n",
    "final_preds = upperbound_baseline(gold_df['luName'], gold_df['gold_cluster_processed'],\n",
    "                                 save_results_path,\n",
    "                                 test_indexes_path=test_indexes_path,\n",
    "                                 k=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-paradise",
   "metadata": {},
   "source": [
    "## Roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df = pd.read_pickle(\"workdir/data/swr_gold_dataset.pkl\")\n",
    "save_results_path = \"workdir/upperbound_results/paper_roles_st\"\n",
    "test_indexes_path = 'workdir/data/swr_gold_dataset_test_split.json'\n",
    "\n",
    "final_preds = upperbound_baseline(gold_df['feText'], gold_df['gold_cluster_patternlemmatized'],\n",
    "                                 save_results_path,\n",
    "                                 test_indexes_path=test_indexes_path,\n",
    "                                 k=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-array",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m src.run_evaluate --results_path=workdir/upperbound_results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
