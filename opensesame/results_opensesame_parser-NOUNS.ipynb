{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "impressed-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lexsub.results_parser import parse_results, ttest_df, ttest_df\n",
    "from lexsub.results_parser import compute_statistical_measures,  compute_statistical_measures_lr\n",
    "from lexsub.results_parser import get_results_opensesame, prettify, prettify2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-radio",
   "metadata": {},
   "source": [
    "### 1SentencePerAnnotation experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "liked-bread",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "seed_exps_dir = \"nExPerSent_nouns_randAllExps\"\n",
    "seed_exp = [(f\"{seed_exps_dir}/01ExPerSent_nouns_rand01\")]\n",
    "\n",
    "\n",
    "expanded_exps_dir='expanded_nExPerSent_nouns_randAllExps'\n",
    "\n",
    "expanded_exps1 = [\n",
    "'01ExPerSent_nouns_rand01_expanded_lu',\n",
    "'01ExPerSent_nouns_rand01_expanded_nouns-10pc',\n",
    "'01ExPerSent_nouns_rand01_expanded_nouns-30pc',\n",
    "'01ExPerSent_nouns_rand01_expanded_nouns-50pc',\n",
    "]\n",
    "\n",
    "expanded_exps2 = [\n",
    "'01ExPerSent_nouns_rand01_expanded_roles',\n",
    "'01ExPerSent_nouns_rand01_expanded_lu_roles_nouns-10pc',\n",
    "'01ExPerSent_nouns_rand01_expanded_lu_roles_nouns-30pc',\n",
    "'01ExPerSent_nouns_rand01_expanded_lu_roles_nouns-50pc',\n",
    "]\n",
    "\n",
    "pipeline1 = 'lugold_rolegold_nltk_nolemma_N2'\n",
    "pipeline2 = 'lugold_rolegold_nltk_nolemma_role_stopwords_N2'\n",
    "\n",
    "\n",
    "preds_model = 'xlnet_embs_hypers'\n",
    "exps11 = [f'{expanded_exps_dir}/{exp}/{preds_model}/{pipeline1}' for exp in expanded_exps1]\n",
    "exps12 = [f'{expanded_exps_dir}/{exp}/{preds_model}/{pipeline2}' for exp in expanded_exps2]\n",
    "\n",
    "exps11.extend(exps12)\n",
    "\n",
    "preds_model = 'bert'\n",
    "exps21 = [f'{expanded_exps_dir}/{exp}/{preds_model}/{pipeline1}' for exp in expanded_exps1]\n",
    "exps22 = [f'{expanded_exps_dir}/{exp}/{preds_model}/{pipeline2}' for exp in expanded_exps2]\n",
    "\n",
    "exps21.extend(exps22)\n",
    "\n",
    "\n",
    "exps = seed_exp\n",
    "exps.extend(exps11)\n",
    "exps.extend(exps21)\n",
    "\n",
    "\n",
    "all_exps = exps\n",
    "print(len(all_exps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "geographic-plastic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>preds_model</th>\n",
       "      <th>pipeline</th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>exp_path</th>\n",
       "      <th>run#</th>\n",
       "      <th>f1</th>\n",
       "      <th>pre</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td></td>\n",
       "      <td>01ExPerSent-nouns-rand01</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert</td>\n",
       "      <td>lugold_rolegold_nltk_nolemma_N2</td>\n",
       "      <td>augmented-lexical unit</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert</td>\n",
       "      <td>lugold_rolegold_nltk_nolemma_N2</td>\n",
       "      <td>augmented-nouns-10pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert</td>\n",
       "      <td>lugold_rolegold_nltk_nolemma_N2</td>\n",
       "      <td>augmented-nouns-30pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bert</td>\n",
       "      <td>lugold_rolegold_nltk_nolemma_N2</td>\n",
       "      <td>augmented-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bert</td>\n",
       "      <td>lugold_rolegold_nltk_nolemma_role_stopwords_N2</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-10pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bert</td>\n",
       "      <td>lugold_rolegold_nltk_nolemma_role_stopwords_N2</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-30pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bert</td>\n",
       "      <td>lugold_rolegold_nltk_nolemma_role_stopwords_N2</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bert</td>\n",
       "      <td>lugold_rolegold_nltk_nolemma_role_stopwords_N2</td>\n",
       "      <td>augmented-roles</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>lugold_rolegold_nltk_nolemma_N2</td>\n",
       "      <td>augmented-lexical unit</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>lugold_rolegold_nltk_nolemma_N2</td>\n",
       "      <td>augmented-nouns-10pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>lugold_rolegold_nltk_nolemma_N2</td>\n",
       "      <td>augmented-nouns-30pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>lugold_rolegold_nltk_nolemma_N2</td>\n",
       "      <td>augmented-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>lugold_rolegold_nltk_nolemma_role_stopwords_N2</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-10pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>lugold_rolegold_nltk_nolemma_role_stopwords_N2</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-30pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>lugold_rolegold_nltk_nolemma_role_stopwords_N2</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>lugold_rolegold_nltk_nolemma_role_stopwords_N2</td>\n",
       "      <td>augmented-roles</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          preds_model                                        pipeline  \\\n",
       "                                                                        \n",
       "0                base                                                   \n",
       "1                bert                 lugold_rolegold_nltk_nolemma_N2   \n",
       "2                bert                 lugold_rolegold_nltk_nolemma_N2   \n",
       "3                bert                 lugold_rolegold_nltk_nolemma_N2   \n",
       "4                bert                 lugold_rolegold_nltk_nolemma_N2   \n",
       "5                bert  lugold_rolegold_nltk_nolemma_role_stopwords_N2   \n",
       "6                bert  lugold_rolegold_nltk_nolemma_role_stopwords_N2   \n",
       "7                bert  lugold_rolegold_nltk_nolemma_role_stopwords_N2   \n",
       "8                bert  lugold_rolegold_nltk_nolemma_role_stopwords_N2   \n",
       "9   xlnet_embs_hypers                 lugold_rolegold_nltk_nolemma_N2   \n",
       "10  xlnet_embs_hypers                 lugold_rolegold_nltk_nolemma_N2   \n",
       "11  xlnet_embs_hypers                 lugold_rolegold_nltk_nolemma_N2   \n",
       "12  xlnet_embs_hypers                 lugold_rolegold_nltk_nolemma_N2   \n",
       "13  xlnet_embs_hypers  lugold_rolegold_nltk_nolemma_role_stopwords_N2   \n",
       "14  xlnet_embs_hypers  lugold_rolegold_nltk_nolemma_role_stopwords_N2   \n",
       "15  xlnet_embs_hypers  lugold_rolegold_nltk_nolemma_role_stopwords_N2   \n",
       "16  xlnet_embs_hypers  lugold_rolegold_nltk_nolemma_role_stopwords_N2   \n",
       "\n",
       "                                    dataset   task exp_path  run#    f1   pre  \\\n",
       "                                                      count count count count   \n",
       "0                  01ExPerSent-nouns-rand01  argid       10    10    10    10   \n",
       "1                    augmented-lexical unit  argid       10    10    10    10   \n",
       "2                      augmented-nouns-10pc  argid       10    10    10    10   \n",
       "3                      augmented-nouns-30pc  argid       10    10    10    10   \n",
       "4                      augmented-nouns-50pc  argid       10    10    10    10   \n",
       "5   augmented-lexical unit-roles-nouns-10pc  argid       10    10    10    10   \n",
       "6   augmented-lexical unit-roles-nouns-30pc  argid       10    10    10    10   \n",
       "7   augmented-lexical unit-roles-nouns-50pc  argid       10    10    10    10   \n",
       "8                           augmented-roles  argid       10    10    10    10   \n",
       "9                    augmented-lexical unit  argid       10    10    10    10   \n",
       "10                     augmented-nouns-10pc  argid       10    10    10    10   \n",
       "11                     augmented-nouns-30pc  argid       10    10    10    10   \n",
       "12                     augmented-nouns-50pc  argid       10    10    10    10   \n",
       "13  augmented-lexical unit-roles-nouns-10pc  argid       10    10    10    10   \n",
       "14  augmented-lexical unit-roles-nouns-30pc  argid       10    10    10    10   \n",
       "15  augmented-lexical unit-roles-nouns-50pc  argid       10    10    10    10   \n",
       "16                          augmented-roles  argid       10    10    10    10   \n",
       "\n",
       "     rec  \n",
       "   count  \n",
       "0     10  \n",
       "1     10  \n",
       "2     10  \n",
       "3     10  \n",
       "4     10  \n",
       "5     10  \n",
       "6     10  \n",
       "7     10  \n",
       "8     10  \n",
       "9     10  \n",
       "10    10  \n",
       "11    10  \n",
       "12    10  \n",
       "13    10  \n",
       "14    10  \n",
       "15    10  \n",
       "16    10  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_model_dir = '../parser_workdir/step_logs'\n",
    "\n",
    "# df = get_results_opensesame(all_exps, \n",
    "#                  output_model_dir,\n",
    "#                  task_name=\"targetid\")\n",
    "\n",
    "# df = get_results_opensesame(all_exps, \n",
    "#                  output_model_dir,\n",
    "#                  task_name=\"frameid\")\n",
    "\n",
    "df = get_results_opensesame(all_exps, \n",
    "                 output_model_dir,\n",
    "                 task_name=\"argid\")\n",
    "\n",
    "df = prettify(df)\n",
    "\n",
    "\n",
    "\n",
    "columns = ['preds_model', 'pipeline', 'dataset', 'task', 'f1', 'pre', 'rec']\n",
    "columns = ['preds_model', 'pipeline', 'dataset', 'task', 'f1']\n",
    "# df = df[columns]\n",
    "df\n",
    "\n",
    "# check number of runs per dataset/preds_model\n",
    "\n",
    "group_columns = ['preds_model', 'pipeline', 'dataset', 'task']\n",
    "dfg=df.groupby(group_columns, as_index=False).agg(['count']).reset_index()\n",
    "\n",
    "dfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = compute_statistical_measures(df)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-moldova",
   "metadata": {},
   "source": [
    "## Visualize - Learning Curve over  F1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-gazette",
   "metadata": {},
   "source": [
    "### List of paths to experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "willing-screening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "seed_exps_dir = \"nPc_nouns_randAllExps\"\n",
    "\n",
    "seed_exps = \"\"\"010pc_nouns\n",
    "020pc_nouns\n",
    "030pc_nouns\n",
    "040pc_nouns\n",
    "050pc_nouns\n",
    "100pc_nouns\"\"\".split('\\n')\n",
    "\n",
    "seed_exps = [f\"{seed_exps_dir}/{exp}\" for exp in seed_exps]\n",
    "\n",
    "\n",
    "expanded_exps_dir = 'expanded_nPc_nouns_randAllExps'\n",
    "\n",
    "expanded_exps1 = \"\"\"010pc_nouns_expanded_nouns-50pc\n",
    "020pc_nouns_expanded_nouns-50pc\n",
    "030pc_nouns_expanded_nouns-50pc\n",
    "040pc_nouns_expanded_nouns-50pc\n",
    "050pc_nouns_expanded_nouns-50pc\n",
    "100pc_nouns_expanded_nouns-50pc\"\"\".split('\\n')\n",
    "\n",
    "expanded_exps2 = \"\"\"010pc_nouns_expanded_lu_roles_nouns-50pc\n",
    "020pc_nouns_expanded_lu_roles_nouns-50pc\n",
    "030pc_nouns_expanded_lu_roles_nouns-50pc\n",
    "040pc_nouns_expanded_lu_roles_nouns-50pc\n",
    "050pc_nouns_expanded_lu_roles_nouns-50pc\n",
    "100pc_nouns_expanded_lu_roles_nouns-50pc\"\"\".split('\\n')\n",
    "\n",
    "pipeline1 = 'lugold_rolegold_nltk_nolemma_N2'\n",
    "pipeline2 = 'lugold_rolegold_nltk_nolemma_role_stopwords_N2'\n",
    "\n",
    "preds_model = 'xlnet_embs_hypers'\n",
    "exps11 = [f'{expanded_exps_dir}/{exp}/{preds_model}/{pipeline1}' for exp in expanded_exps1]\n",
    "exps12 = [f'{expanded_exps_dir}/{exp}/{preds_model}/{pipeline2}' for exp in expanded_exps2]\n",
    "\n",
    "exps11.extend(exps12)\n",
    "\n",
    "preds_model = 'bert'\n",
    "exps21 = [f'{expanded_exps_dir}/{exp}/{preds_model}/{pipeline1}' for exp in expanded_exps1]\n",
    "exps22 = [f'{expanded_exps_dir}/{exp}/{preds_model}/{pipeline2}' for exp in expanded_exps2]\n",
    "\n",
    "exps21.extend(exps22)\n",
    "\n",
    "exps = seed_exps\n",
    "exps.extend(exps11)\n",
    "exps.extend(exps21)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "all_exps = exps\n",
    "\n",
    "print(len(all_exps))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "perfect-thailand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>preds_model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>exp_path</th>\n",
       "      <th>run#</th>\n",
       "      <th>f1</th>\n",
       "      <th>pre</th>\n",
       "      <th>rec</th>\n",
       "      <th>pipeline</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>nPercentData</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>base</td>\n",
       "      <td>nPercentData</td>\n",
       "      <td>argid</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>base</td>\n",
       "      <td>nPercentData</td>\n",
       "      <td>argid</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>base</td>\n",
       "      <td>nPercentData</td>\n",
       "      <td>argid</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>base</td>\n",
       "      <td>nPercentData</td>\n",
       "      <td>argid</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>base</td>\n",
       "      <td>nPercentData</td>\n",
       "      <td>argid</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bert</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bert</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bert</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bert</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bert</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bert</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bert</td>\n",
       "      <td>augmented-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bert</td>\n",
       "      <td>augmented-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bert</td>\n",
       "      <td>augmented-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bert</td>\n",
       "      <td>augmented-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bert</td>\n",
       "      <td>augmented-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bert</td>\n",
       "      <td>augmented-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>augmented-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>augmented-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>augmented-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>augmented-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>augmented-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>augmented-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          preds_model                                  dataset   task  \\\n",
       "                                                                        \n",
       "0                base                             nPercentData  argid   \n",
       "1                base                             nPercentData  argid   \n",
       "2                base                             nPercentData  argid   \n",
       "3                base                             nPercentData  argid   \n",
       "4                base                             nPercentData  argid   \n",
       "5                base                             nPercentData  argid   \n",
       "6                bert  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "7                bert  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "8                bert  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "9                bert  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "10               bert  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "11               bert  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "12               bert                     augmented-nouns-50pc  argid   \n",
       "13               bert                     augmented-nouns-50pc  argid   \n",
       "14               bert                     augmented-nouns-50pc  argid   \n",
       "15               bert                     augmented-nouns-50pc  argid   \n",
       "16               bert                     augmented-nouns-50pc  argid   \n",
       "17               bert                     augmented-nouns-50pc  argid   \n",
       "18  xlnet_embs_hypers  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "19  xlnet_embs_hypers  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "20  xlnet_embs_hypers  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "21  xlnet_embs_hypers  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "22  xlnet_embs_hypers  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "23  xlnet_embs_hypers  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "24  xlnet_embs_hypers                     augmented-nouns-50pc  argid   \n",
       "25  xlnet_embs_hypers                     augmented-nouns-50pc  argid   \n",
       "26  xlnet_embs_hypers                     augmented-nouns-50pc  argid   \n",
       "27  xlnet_embs_hypers                     augmented-nouns-50pc  argid   \n",
       "28  xlnet_embs_hypers                     augmented-nouns-50pc  argid   \n",
       "29  xlnet_embs_hypers                     augmented-nouns-50pc  argid   \n",
       "\n",
       "   sample_size exp_path  run#    f1   pre   rec pipeline  \n",
       "                  count count count count count    count  \n",
       "0           10       10    10    10    10    10       10  \n",
       "1           20       10    10    10    10    10       10  \n",
       "2           30       10    10    10    10    10       10  \n",
       "3           40       10    10    10    10    10       10  \n",
       "4           50       10    10    10    10    10       10  \n",
       "5          100       10    10    10    10    10       10  \n",
       "6           10       10    10    10    10    10       10  \n",
       "7           20       10    10    10    10    10       10  \n",
       "8           30       10    10    10    10    10       10  \n",
       "9           40       10    10    10    10    10       10  \n",
       "10          50       10    10    10    10    10       10  \n",
       "11         100       10    10    10    10    10       10  \n",
       "12          10       10    10    10    10    10       10  \n",
       "13          20       10    10    10    10    10       10  \n",
       "14          30       10    10    10    10    10       10  \n",
       "15          40       10    10    10    10    10       10  \n",
       "16          50       10    10    10    10    10       10  \n",
       "17         100       10    10    10    10    10       10  \n",
       "18          10       10    10    10    10    10       10  \n",
       "19          20       10    10    10    10    10       10  \n",
       "20          30       10    10    10    10    10       10  \n",
       "21          40       10    10    10    10    10       10  \n",
       "22          50       10    10    10    10    10       10  \n",
       "23         100       10    10    10    10    10       10  \n",
       "24          10       10    10    10    10    10       10  \n",
       "25          20       10    10    10    10    10       10  \n",
       "26          30       10    10    10    10    10       10  \n",
       "27          40       10    10    10    10    10       10  \n",
       "28          50       10    10    10    10    10       10  \n",
       "29         100       10    10    10    10    10       10  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_model_dir = '../parser_workdir/step_logs'\n",
    "df = get_results_opensesame(all_exps, output_model_dir)\n",
    "\n",
    "\n",
    "\n",
    "df = prettify2(df)\n",
    "# df\n",
    "# columns = ['preds_model', 'pipeline', 'dataset', 'task', 'sample_size', 'f1', 'pre', 'rec']\n",
    "# group_columns = ['preds_model', 'pipeline', 'dataset', 'task', 'sample_size']\n",
    "\n",
    "columns = ['preds_model', 'dataset', 'task', 'sample_size', 'f1', 'pre', 'rec']\n",
    "group_columns = ['preds_model', 'dataset', 'task', 'sample_size']\n",
    "\n",
    "# df = df[columns]\n",
    "df\n",
    "# #check number of runs per dataset/preds_model\n",
    "dfg=df.groupby(group_columns, as_index=False).agg(['count']).reset_index()\n",
    "\n",
    "dfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "precise-sessions",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>preds_model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>task</th>\n",
       "      <th>sample_size</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">pre</th>\n",
       "      <th colspan=\"2\" halign=\"left\">rec</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base</td>\n",
       "      <td>nPercentData</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>54.40</td>\n",
       "      <td>1.10</td>\n",
       "      <td>58.54</td>\n",
       "      <td>1.16</td>\n",
       "      <td>50.81</td>\n",
       "      <td>1.28</td>\n",
       "      <td>p &gt; 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>base</td>\n",
       "      <td>nPercentData</td>\n",
       "      <td>argid</td>\n",
       "      <td>20</td>\n",
       "      <td>59.70</td>\n",
       "      <td>1.18</td>\n",
       "      <td>61.73</td>\n",
       "      <td>2.15</td>\n",
       "      <td>57.85</td>\n",
       "      <td>1.47</td>\n",
       "      <td>p &gt; 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>base</td>\n",
       "      <td>nPercentData</td>\n",
       "      <td>argid</td>\n",
       "      <td>30</td>\n",
       "      <td>62.33</td>\n",
       "      <td>0.62</td>\n",
       "      <td>63.44</td>\n",
       "      <td>1.65</td>\n",
       "      <td>61.29</td>\n",
       "      <td>0.87</td>\n",
       "      <td>p &gt; 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>base</td>\n",
       "      <td>nPercentData</td>\n",
       "      <td>argid</td>\n",
       "      <td>40</td>\n",
       "      <td>63.70</td>\n",
       "      <td>0.98</td>\n",
       "      <td>64.92</td>\n",
       "      <td>2.18</td>\n",
       "      <td>62.58</td>\n",
       "      <td>1.37</td>\n",
       "      <td>p &gt; 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>base</td>\n",
       "      <td>nPercentData</td>\n",
       "      <td>argid</td>\n",
       "      <td>50</td>\n",
       "      <td>64.84</td>\n",
       "      <td>0.45</td>\n",
       "      <td>67.15</td>\n",
       "      <td>1.39</td>\n",
       "      <td>62.71</td>\n",
       "      <td>0.84</td>\n",
       "      <td>p &gt; 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>base</td>\n",
       "      <td>nPercentData</td>\n",
       "      <td>argid</td>\n",
       "      <td>100</td>\n",
       "      <td>67.89</td>\n",
       "      <td>0.50</td>\n",
       "      <td>68.65</td>\n",
       "      <td>1.23</td>\n",
       "      <td>67.16</td>\n",
       "      <td>0.75</td>\n",
       "      <td>p &gt; 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bert</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>57.72</td>\n",
       "      <td>1.25</td>\n",
       "      <td>62.08</td>\n",
       "      <td>2.84</td>\n",
       "      <td>54.02</td>\n",
       "      <td>1.53</td>\n",
       "      <td>p &lt; 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bert</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>20</td>\n",
       "      <td>61.46</td>\n",
       "      <td>0.91</td>\n",
       "      <td>63.44</td>\n",
       "      <td>1.95</td>\n",
       "      <td>59.64</td>\n",
       "      <td>0.95</td>\n",
       "      <td>p &lt; 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bert</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>30</td>\n",
       "      <td>63.90</td>\n",
       "      <td>0.92</td>\n",
       "      <td>65.60</td>\n",
       "      <td>2.20</td>\n",
       "      <td>62.34</td>\n",
       "      <td>1.03</td>\n",
       "      <td>p &lt; 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bert</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>40</td>\n",
       "      <td>65.33</td>\n",
       "      <td>0.71</td>\n",
       "      <td>68.00</td>\n",
       "      <td>1.63</td>\n",
       "      <td>62.89</td>\n",
       "      <td>1.08</td>\n",
       "      <td>p &lt; 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bert</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>50</td>\n",
       "      <td>66.36</td>\n",
       "      <td>0.88</td>\n",
       "      <td>67.64</td>\n",
       "      <td>1.79</td>\n",
       "      <td>65.15</td>\n",
       "      <td>0.48</td>\n",
       "      <td>p &lt; 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bert</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>100</td>\n",
       "      <td>69.07</td>\n",
       "      <td>0.48</td>\n",
       "      <td>70.04</td>\n",
       "      <td>1.06</td>\n",
       "      <td>68.15</td>\n",
       "      <td>0.89</td>\n",
       "      <td>p &lt; 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>10</td>\n",
       "      <td>58.17</td>\n",
       "      <td>1.13</td>\n",
       "      <td>61.42</td>\n",
       "      <td>1.85</td>\n",
       "      <td>55.28</td>\n",
       "      <td>1.19</td>\n",
       "      <td>p &lt; 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>20</td>\n",
       "      <td>61.84</td>\n",
       "      <td>0.97</td>\n",
       "      <td>64.95</td>\n",
       "      <td>2.85</td>\n",
       "      <td>59.12</td>\n",
       "      <td>1.76</td>\n",
       "      <td>p &lt; 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>30</td>\n",
       "      <td>64.43</td>\n",
       "      <td>0.76</td>\n",
       "      <td>66.18</td>\n",
       "      <td>2.84</td>\n",
       "      <td>62.89</td>\n",
       "      <td>1.53</td>\n",
       "      <td>p &lt; 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>40</td>\n",
       "      <td>65.76</td>\n",
       "      <td>0.20</td>\n",
       "      <td>67.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>64.18</td>\n",
       "      <td>0.54</td>\n",
       "      <td>p &lt; 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>50</td>\n",
       "      <td>66.57</td>\n",
       "      <td>0.73</td>\n",
       "      <td>68.26</td>\n",
       "      <td>1.57</td>\n",
       "      <td>65.01</td>\n",
       "      <td>1.09</td>\n",
       "      <td>p &lt; 0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>xlnet_embs_hypers</td>\n",
       "      <td>augmented-lexical unit-roles-nouns-50pc</td>\n",
       "      <td>argid</td>\n",
       "      <td>100</td>\n",
       "      <td>69.18</td>\n",
       "      <td>0.54</td>\n",
       "      <td>69.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>68.53</td>\n",
       "      <td>0.97</td>\n",
       "      <td>p &lt; 0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          preds_model                                  dataset   task  \\\n",
       "                                                                        \n",
       "0                base                             nPercentData  argid   \n",
       "1                base                             nPercentData  argid   \n",
       "2                base                             nPercentData  argid   \n",
       "3                base                             nPercentData  argid   \n",
       "4                base                             nPercentData  argid   \n",
       "5                base                             nPercentData  argid   \n",
       "6                bert  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "7                bert  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "8                bert  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "9                bert  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "10               bert  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "11               bert  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "12  xlnet_embs_hypers  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "13  xlnet_embs_hypers  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "14  xlnet_embs_hypers  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "15  xlnet_embs_hypers  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "16  xlnet_embs_hypers  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "17  xlnet_embs_hypers  augmented-lexical unit-roles-nouns-50pc  argid   \n",
       "\n",
       "   sample_size     f1          pre          rec         p_value  \n",
       "                 mean   std   mean   std   mean   std            \n",
       "0           10  54.40  1.10  58.54  1.16  50.81  1.28  p > 0.01  \n",
       "1           20  59.70  1.18  61.73  2.15  57.85  1.47  p > 0.01  \n",
       "2           30  62.33  0.62  63.44  1.65  61.29  0.87  p > 0.01  \n",
       "3           40  63.70  0.98  64.92  2.18  62.58  1.37  p > 0.01  \n",
       "4           50  64.84  0.45  67.15  1.39  62.71  0.84  p > 0.01  \n",
       "5          100  67.89  0.50  68.65  1.23  67.16  0.75  p > 0.01  \n",
       "6           10  57.72  1.25  62.08  2.84  54.02  1.53  p < 0.01  \n",
       "7           20  61.46  0.91  63.44  1.95  59.64  0.95  p < 0.01  \n",
       "8           30  63.90  0.92  65.60  2.20  62.34  1.03  p < 0.01  \n",
       "9           40  65.33  0.71  68.00  1.63  62.89  1.08  p < 0.01  \n",
       "10          50  66.36  0.88  67.64  1.79  65.15  0.48  p < 0.01  \n",
       "11         100  69.07  0.48  70.04  1.06  68.15  0.89  p < 0.01  \n",
       "12          10  58.17  1.13  61.42  1.85  55.28  1.19  p < 0.01  \n",
       "13          20  61.84  0.97  64.95  2.85  59.12  1.76  p < 0.01  \n",
       "14          30  64.43  0.76  66.18  2.84  62.89  1.53  p < 0.01  \n",
       "15          40  65.76  0.20  67.42  0.50  64.18  0.54  p < 0.01  \n",
       "16          50  66.57  0.73  68.26  1.57  65.01  1.09  p < 0.01  \n",
       "17         100  69.18  0.54  69.86  0.86  68.53  0.97  p < 0.01  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = compute_statistical_measures_lr(df)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "def results_maps(dfg, \n",
    "                 base_dataset = 'nPercentData',\n",
    "                 base_model=\"base\",\n",
    "                 augmented_datasets = ['augmented-nouns-50pc', 'augmented-lexical unit-roles-nouns-50pc'],\n",
    "                 augmented_models = ['bert', 'xlnet_embs_hypers'],\n",
    "                 eval_measure=\"f1\"):\n",
    "\n",
    "    mean_scores = {}\n",
    "    std_scores = {}\n",
    "    p_values = {}\n",
    "#     base model scores\n",
    "    scores = dfg.loc[(dfg['dataset'] == base_dataset) & (dfg['preds_model'] == base_model)][eval_measure]['mean'].tolist()\n",
    "    mean_scores[base_model] = {base_dataset:scores}\n",
    "\n",
    "    scores = dfg.loc[(dfg['dataset'] == base_dataset) & (dfg['preds_model'] == base_model)][eval_measure]['std'].tolist()\n",
    "    std_scores[base_model] = {base_dataset:scores}\n",
    "\n",
    "# augmented model scores\n",
    "    for m in augmented_models:\n",
    "\n",
    "        all_models_means = {}\n",
    "        for ds in augmented_datasets:\n",
    "            scores = dfg.loc[(dfg['dataset'] == ds) & (dfg['preds_model'] == m)][eval_measure]['mean'].tolist()\n",
    "            all_models_means[ds] = scores\n",
    "\n",
    "        all_models_std = {}\n",
    "        for ds in augmented_datasets:\n",
    "            scores = dfg.loc[(dfg['dataset'] == ds) & (dfg['preds_model'] == m)][eval_measure]['std'].tolist()\n",
    "            all_models_std[ds] = scores\n",
    "\n",
    "        all_models_ps = {}\n",
    "        for ds in augmented_datasets:\n",
    "            scores = dfg.loc[(dfg['dataset'] == ds) & (dfg['preds_model'] == m)]['p_value'].tolist()\n",
    "            all_models_ps[ds] = scores\n",
    "            \n",
    "        mean_scores[m] = all_models_means\n",
    "        std_scores[m] = all_models_std\n",
    "        p_values[m] = all_models_ps\n",
    "        \n",
    "    return mean_scores, std_scores, p_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores, std_scores, p_values = results_maps(results_df)\n",
    "mean_scores, p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "%matplotlib inline\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "N = [10,20,30,40,50, 100]\n",
    "\n",
    "base_model = 'base'\n",
    "augmented_models = ['bert', 'xlnet_embs_hypers']\n",
    "\n",
    "datasets = ['nPercentData', 'augmented-nouns-50pc', 'augmented-lexical unit-roles-nouns-50pc']\n",
    "labels = ['seed', 'augmented-nouns-50pc', 'augmented-lexical unit-roles-nouns-50pc']\n",
    "\n",
    "title = \"Learning Curves\"\n",
    "subtitles = {'bert': 'BERT',\n",
    "            'xlnet_embs_hypers': 'XLNet+embs'}\n",
    "\n",
    "colors = ['k','c', 'y', 'r', 'brown']\n",
    "# ----------------------------------------------------------------------\n",
    "fig, axes = plt.subplots(1, 2, \n",
    "                         dpi=480,\n",
    "                         figsize=(14, 4))\n",
    "\n",
    "for j, m in enumerate(augmented_models):\n",
    "    print(j, m)\n",
    "\n",
    "    axes[j].set_title(f'Substitution model: {subtitles[m]}')\n",
    "    axes[j].set_xlabel('Percentage of training data sampled randomly (dataset: Nouns)')\n",
    "    axes[0].set_ylabel('F1-score (with gold frames)')\n",
    "    axes[j].set_xticks(N)\n",
    "\n",
    "    axes[j].set_yticks(range(50, 80, 1))\n",
    "    axes[j].grid()\n",
    "         \n",
    "    i = -1\n",
    "    for ds, label in zip(datasets, labels):\n",
    "        i += 1\n",
    "        print(ds, label)\n",
    "        if label == 'seed': model = base_model\n",
    "        else:\n",
    "            model = m   \n",
    "            ps = p_values[model][ds]\n",
    "            # ------------------------------- to place P_values on optimally\n",
    "            exp_names = list(mean_scores[model].keys())\n",
    "            max_mean = [max(a,b) for a,b in zip(np.array(mean_scores[model][exp_names[0]]), np.array(mean_scores[model][exp_names[-1]]))]\n",
    "            max_std = [max(a,b) for a,b in zip(np.array(std_scores[model][exp_names[0]]), np.array(std_scores[model][exp_names[-1]]))]\n",
    "#             pY = [x+y for x,y in zip(max_mean, max_std)]\n",
    "            pY = max_mean\n",
    "        #     -------------------------------\n",
    "            \n",
    "\n",
    "        mean = np.array(mean_scores[model][ds])\n",
    "        std = np.array(std_scores[model][ds])\n",
    "        \n",
    "        axes[j].fill_between(N, mean - std,\n",
    "                             mean + std, alpha=0.1,\n",
    "                             color=colors[i])\n",
    "\n",
    "        axes[j].semilogx(N, mean, 'o-', color=colors[i],\n",
    "                     label=labels[i], base=2, nonpositive='clip')\n",
    "        pX = N\n",
    "        p = -1\n",
    "        if i==1:\n",
    "            font = {\n",
    "#                 'family': 'serif',\n",
    "                    'color':  colors[i],\n",
    "                    'weight': 'bold',\n",
    "                    'size': 7\n",
    "                    }\n",
    "            for xx,yy in zip(pX,pY):\n",
    "                p += 1\n",
    "                #   place it below the lines\n",
    "                if xx in [40, 100]:\n",
    "                    axes[j].text(xx,yy-3, ps[p], fontdict=font)        \n",
    "                #  place it above the lines\n",
    "                else:\n",
    "                    axes[j].text(xx,yy+2, ps[p], fontdict=font) \n",
    "        if i==2:\n",
    "            font = {\n",
    "#                 'family': 'serif',\n",
    "                    'color':  colors[i],\n",
    "                    'weight': 'bold',\n",
    "                    'size': 7\n",
    "                    }\n",
    "            for xx,yy in zip(pX,pY):\n",
    "                p += 1\n",
    "                #   place it below the lines\n",
    "                if xx in [40, 100]:\n",
    "                    axes[j].text(xx,yy-3.75, ps[p], fontdict=font)        \n",
    "                #  place it above the lines\n",
    "                else:\n",
    "                    axes[j].text(xx,yy+2.75, ps[p], fontdict=font) \n",
    "   \n",
    "\n",
    "lines_labels = [ax.get_legend_handles_labels() for ax in fig.axes[:1]]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "plt.figlegend( lines, labels, loc = 'lower center', ncol=3, labelspacing=0. , bbox_to_anchor=(0.5, -0.1))\n",
    "# axes.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-music",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
