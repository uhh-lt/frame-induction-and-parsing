{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**module:** lexsub.run_generate_masked_sentences\n",
    "```\n",
    "python -m lexsub.run_generate_masked_sentences --configs $JSON_CONFIGS_FILE_PATH --workers 12\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create json configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_template(name, exps_dir, exp, output_dir, substitute_lu, substitute_role, noun_max, ibn):\n",
    "    return {\"name\":name,\n",
    "            \"args\":{\n",
    "                \"input_exp\": os.path.join(exps_dir, exp),\n",
    "                \"output_exp\": os.path.join(output_dir, name),\n",
    "                \"substitute_lu\":substitute_lu,\n",
    "                \"substitute_role\":substitute_role,\n",
    "                \"noun_max\":f'{noun_max}', \n",
    "                \"ibn\":ibn\n",
    "                }\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# -----------------------------------------------------\n",
    "seed_exps = [\n",
    "    '01ExPerSent_verbs_rand01'\n",
    "]\n",
    "exps_dir='nExPerSent_verbs_randAllExps'\n",
    "output_dir = 'expanded_nExPerSent_verbs_randAllExps'\n",
    "json_file = 'masking_nExPerSent_verbs_randAllExps'\n",
    "# # ---------------------------------------------------\n",
    "# exps_dir = \"nPc_verbs_randAllExps\"\n",
    "# seed_exps = [\n",
    "#     '010pc_verbs',\n",
    "#     '020pc_verbs',\n",
    "#     '030pc_verbs',\n",
    "#     '040pc_verbs',\n",
    "#     '050pc_verbs',\n",
    "#     '100pc_verbs'\n",
    "# ]\n",
    "# output_dir = 'expanded_nPc_verbs_randAllExps'\n",
    "# json_file = 'masking_nPc_verbs_randAllExps'\n",
    "# ---------------------------------------------------\n",
    "# seed_exps = [\n",
    "#     '01ExPerSent_nouns_rand01',\n",
    "# ]\n",
    "# exps_dir='nExPerSent_nouns_randAllExps'\n",
    "# output_dir = 'expanded_nExPerSent_nouns_randAllExps'\n",
    "# json_file = 'masking_nExPerSent_nouns_randAllExps'\n",
    "\n",
    "# # ---------------------------------------------------\n",
    "# seed_exps = [\n",
    "# '010pc_nouns',\n",
    "# '020pc_nouns',\n",
    "# '030pc_nouns',\n",
    "# '040pc_nouns',\n",
    "# '050pc_nouns',\n",
    "# '100pc_nouns'\n",
    "# ]\n",
    "# exps_dir = \"nPc_nouns_randAllExps\"\n",
    "# output_dir = 'expanded_nPc_nouns_randAllExps'\n",
    "# json_file = 'masking_nPc_nouns_randAllExps'\n",
    "# # ---------------------------------------------------\n",
    "\n",
    "\n",
    "configs_output = 'configurations/configs_augment'\n",
    "nouns = [0.1,0.3,0.5]\n",
    "\n",
    "# nouns = [0.3, 0.5]\n",
    "\n",
    "\n",
    "expanded_configs = [\n",
    "    'lu', \n",
    "    'roles', \n",
    "    'nouns',\n",
    "    'lu-roles-nouns',\n",
    "]\n",
    "# --------------------------------------------------------------------    \n",
    "exp_configs= []\n",
    "\n",
    "for exp in seed_exps:\n",
    "    \n",
    "    base_name = f'{exp}_expanded'\n",
    "    \n",
    "    for config in expanded_configs:\n",
    "        \n",
    "        name = base_name\n",
    "        \n",
    "#         print(config)\n",
    "        substitute_lu = False\n",
    "        substitute_role = False\n",
    "        ibn = True\n",
    "        noun_max = 0\n",
    "        \n",
    "        if 'lu' in config:\n",
    "            \n",
    "            substitute_lu = True\n",
    "            name = f'{base_name}_lu'\n",
    "        \n",
    "        if 'roles' in config:\n",
    "            substitute_role = True\n",
    "            name = f'{name}_roles'\n",
    "        \n",
    "        if 'nouns' in config:     \n",
    "              \n",
    "            for noun_max in nouns:\n",
    "                if noun_max<=0: continue \n",
    "                \n",
    "                name_n = f'{name}_nouns-{int(100*noun_max)}pc'\n",
    "                ibn = True\n",
    "                if 'nouns-ooa' in config:\n",
    "                    name_n = f'{name_n}-ooa'\n",
    "                    ibn = False\n",
    "                    \n",
    "                exp_configs.append(mask_template(name_n, exps_dir, exp, output_dir, \n",
    "                                            substitute_lu, substitute_role, noun_max, ibn))    \n",
    "\n",
    "        elif name!=base_name:\n",
    "            exp_configs.append(mask_template(name, exps_dir, exp, output_dir, \n",
    "                                            substitute_lu, substitute_role, noun_max, ibn))\n",
    "\n",
    "                            \n",
    " \n",
    "print(f'json file:{json_file}')\n",
    "print(len(exp_configs))\n",
    "exp_names =[exp['name'] for exp in exp_configs]\n",
    "# print(','.join(exp_names))\n",
    "\n",
    "with open(f'{configs_output}/{json_file}.json', 'w') as fp:\n",
    "        json.dump(exp_configs, fp, indent=4)\n",
    "        \n",
    "    \n",
    "exp_configs[0]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocess and do final augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**module:** lexsub.run_augment_conll_sentences\n",
    "```\n",
    "python -m lexsub.run_augment_conll_sentences --configs $JSON_CONFIGS_PATH --workers 12\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create json configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_template(name, exps_dir, exp, output_dir, model_type, proc_funcs, parser, match_gold, pipeline, N, postprocess, final_preds_path):\n",
    "#     print(name)\n",
    "    return {\"name\":name,\n",
    "            \"args\":{\n",
    "                \"input_exp\": os.path.join(exps_dir, exp),\n",
    "                \"output_exp\": os.path.join(output_dir, name),\n",
    "                \"preds_model\": model_type,                                \n",
    "                \"proc_funcs\":proc_funcs,  \n",
    "                \"parser\":parser,\n",
    "                \"match_lugold\":match_gold[0],                                \n",
    "                \"match_rolegold\":match_gold[1],\n",
    "                \"pipeline\":pipeline,\n",
    "                \"N\":N,\n",
    "                \"postprocess\":postprocess,\n",
    "                \"final_preds_path\":final_preds_path\n",
    "                }\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# ---------------------------------------------------\n",
    "seed_exps = [\n",
    "    '01ExPerSent_verbs_rand01',\n",
    "]\n",
    "exps_dir='nExPerSent_verbs_randAllExps'\n",
    "output_dir = 'expanded_nExPerSent_verbs_randAllExps'\n",
    "\n",
    "# # ---------------------------------------------------\n",
    "\n",
    "# seed_exps = [\n",
    "#     '010pc_verbs',\n",
    "#     '020pc_verbs',\n",
    "#     '030pc_verbs',\n",
    "#     '040pc_verbs',\n",
    "#     '050pc_verbs',\n",
    "#     '100pc_verbs'\n",
    "# ]\n",
    "# exps_dir = \"nPc_verbs_randAllExps\"\n",
    "# output_dir = 'expanded_nPc_verbs_randAllExps'\n",
    "# # ---------------------------------------------------\n",
    "# seed_exps = [\n",
    "#     '01ExPerSent_nouns_rand01'\n",
    "# ]\n",
    "# exps_dir='nExPerSent_nouns_randAllExps'\n",
    "# output_dir = 'expanded_nExPerSent_nouns_randAllExps'\n",
    "\n",
    "# # ---------------------------------------------------\n",
    "\n",
    "# seed_exps = [\n",
    "# '010pc_nouns',\n",
    "# '020pc_nouns',\n",
    "# '030pc_nouns',\n",
    "# '040pc_nouns',\n",
    "# '050pc_nouns',\n",
    "# '100pc_nouns'\n",
    "# ]\n",
    "# exps_dir = \"nPc_nouns_randAllExps\"\n",
    "# output_dir = 'expanded_nPc_nouns_randAllExps'\n",
    "# ---------------------------------------------\n",
    "# nouns = [0.3,0.5]\n",
    "nouns = [0.1,0.3,0.5]\n",
    "\n",
    "\n",
    "preds_models = [\n",
    "# 'dt,\n",
    "# 'embs',\n",
    "# 'melamud_baladd',\n",
    "'bert',\n",
    "'xlnet_embs_hypers'\n",
    "]\n",
    "model = ''\n",
    "\n",
    "match_gold, gold_prefix = [True, True], 'lugold_rolegold'\n",
    "if gold_prefix != '': gold_prefix = gold_prefix+'_'\n",
    "N = 2\n",
    "postprocess = False\n",
    "parser = 'nltk'\n",
    "# proc_funcs = 'nolemma'\n",
    "proc_funcs = 'nolemma_role_stopwords'\n",
    "\n",
    "pipeline = f'{gold_prefix}{parser}_{proc_funcs}_N{N}'\n",
    "preds_pipeline = f'{parser}_{proc_funcs}' \n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "json_file = f'{model}{output_dir}_{pipeline}.json'\n",
    "configs_output = \"configurations/configs_augment\" \n",
    "# --------------------------------------------------------------------    \n",
    "expanded_configs = [\n",
    "#     'lu', \n",
    "    'roles', \n",
    "#     'nouns',\n",
    "    'lu-roles-nouns',\n",
    "]\n",
    "\n",
    "exp_configs= []\n",
    "\n",
    "for exp in seed_exps:\n",
    "#     print(exp)\n",
    "    for model_type in preds_models:\n",
    "        \n",
    "        base_name = f'{exp}_expanded'\n",
    "        \n",
    "        for config in expanded_configs:\n",
    "            \n",
    "#             print(config)\n",
    "            \n",
    "            if not 'nouns' in config: \n",
    "                if config == 'lu':\n",
    "                    name = f'{base_name}_lu'\n",
    "                elif config == 'roles':\n",
    "                    name = f'{base_name}_roles'\n",
    "                elif config == 'lu-roles':\n",
    "                    name = f'{base_name}_lu_roles'\n",
    "                else: continue\n",
    "#                 print(name)\n",
    "                final_preds_path = f'{output_dir}/{name}/{model_type}/{preds_pipeline}_final_predictions.pkl'\n",
    "                exp_configs.append(augmentation_template(name, exps_dir, exp, output_dir, model_type, \n",
    "                                              proc_funcs, parser,match_gold, pipeline, N, postprocess, final_preds_path))\n",
    "            else: \n",
    "                \n",
    "                for noun_max in nouns:\n",
    "                    if noun_max<=0: continue        \n",
    "\n",
    "                    if config == 'nouns':\n",
    "                        name = f'{base_name}_nouns-{int(100*noun_max)}pc' \n",
    "                    elif config == 'nouns-ooa':\n",
    "                        name = f'{base_name}_nouns-{int(100*noun_max)}pc-ooa'\n",
    "                    elif config == 'roles-nouns':\n",
    "                        name = f'{base_name}_roles_nouns-{int(100*noun_max)}pc'\n",
    "                    elif config == 'roles-nouns-ooa':\n",
    "                        name = f'{base_name}_roles_nouns-{int(100*noun_max)}pc-ooa'\n",
    "                    elif config == 'lu-nouns':\n",
    "                        name = f'{base_name}_lu-nouns-{int(100*noun_max)}pc'\n",
    "                    elif config == 'lu-nouns-ooa':\n",
    "                        name = f'{base_name}_lu_nouns-{int(100*noun_max)}pc-ooa'\n",
    "                    elif config == 'lu-roles-nouns':\n",
    "                        name = f'{base_name}_lu_roles_nouns-{int(100*noun_max)}pc'\n",
    "                    elif config == 'lu-roles-nouns-ooa':\n",
    "                        name = f'{base_name}_lu_roles_nouns-{int(100*noun_max)}pc-ooa'\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "#                     print(name)\n",
    "                    final_preds_path = f'{output_dir}/{name}/{model_type}/{preds_pipeline}_final_predictions.pkl'\n",
    "                    exp_configs.append(augmentation_template(name, exps_dir, exp, output_dir, model_type, \n",
    "                                                proc_funcs, parser,match_gold, pipeline, N, postprocess, final_preds_path))\n",
    "\n",
    "        \n",
    "print(f'json file: {json_file}')\n",
    "print(len(exp_configs))\n",
    "exp_names =[exp['name'] for exp in exp_configs]\n",
    "# print(','.join(exp_names))\n",
    "\n",
    "with open(f'{configs_output}/{json_file}', 'w') as fp:\n",
    "        json.dump(exp_configs, fp, indent=4)\n",
    "        \n",
    "        \n",
    "exp_configs[0]        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
