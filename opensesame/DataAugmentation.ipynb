{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation\n",
    "**module**: lexsub.augment_conll.py\n",
    "currently it is configured to use basic models without any targetword injections such as dynamic patterns\n",
    "\n",
    "```\n",
    "augment_conllFile(input_file, output_file=None, model_type='bert-large-cased', N=2, substitute_lu=True, substitute_role=False, noun_max=0, ibn=False, proc_funcs=PROC_FUNCS_OPTIONS['lemma'],match_lugold=True, match_rolegold=False, verbose=False)\n",
    "```\n",
    "here:\n",
    "- model_type: if string, predictor will be loaded as defined in src.run_predict.load_predictor\n",
    "- N: number of substitutes to expand\n",
    "- noun_max: a float value to specify percentage of sentence tokens to be substitutes as nouns\n",
    "- ibn: whether to substitutes tokens that are part of some roles\n",
    "- proc_funcs: a dictionary to specify post_process pipelines to be used for lu, role and noun, see PROC_FUNCS_OPTIONS in  run_generate_substitutes.py for more details, **lemma** value is used for all experiments reported in paper\n",
    "    \n",
    "\n",
    "use **run_augment_conll.py** to run multiple experiements using json file\n",
    "See an example below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. mask sentences\n",
    "mask potential words in each sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m lexsub.generate_masked_sentences \\\n",
    "--input_exp='nExPerSent_verbs_randAllExps/01ExPerSent_verbs_rand01'\\\n",
    "--output_exp='expanded_nExPerSent_verbs_randAllExps/01ExPerSent_verbs_rand01_expanded_lu_roles_nouns-50pc'\\\n",
    "--data_dir='data/open_sesame_v1_data/fn1.7'\\\n",
    "--substitute_lu=True\\\n",
    "--substitute_role=True\\\n",
    "--noun_max=0.5\\\n",
    "--ibn=True\\\n",
    "--verbose=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. predict substitutes\n",
    "predict substitutes using some predictor and save predictions.pkl within each ```$output_exp/$preds_model``` directory, where ```$preds_model``` represents the predictor model\n",
    "\n",
    "see run_experiment notebook for details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. augment masked sentences with predicted substitutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m lexsub.augment_conll_sentences \\\n",
    "--input_exp='nExPerSent_verbs_randAllExps/01ExPerSent_verbs_rand01'\\\n",
    "--output_exp='expanded_nExPerSent_verbs_randAllExps/01ExPerSent_verbs_rand01_expanded_lu_roles_nouns-50pc'\\\n",
    "--data_dir='data/open_sesame_v1_data/fn1.7'\\\n",
    "--preds_model='xlnet_embs_hypers'\\\n",
    "--match_lugold=True\\\n",
    "--match_rolegold=True\\\n",
    "--proc_funcs='lemma'\\\n",
    "--postprocess=False\\ # optional, not needed if predictions are already processed \n",
    "--pipeline='lugold_rolegold_nolemma'\\\n",
    "--N=2\\\n",
    "--verbose=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running end-to-end experiment \n",
    "will only save output conll file\n",
    "\n",
    "- slow and inefficient, not useful for large number of experiments, advisable to create one main file using all data of verbs/nouns and mark all words at once, do the prediction using all predictions model and post process once for each word_type [verb,noun,role]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m lexsub.augment_conll \\\n",
    "--input_exp='nExPerSent_verbs_randAllExps/01ExPerSent_verbs_rand01'\\\n",
    "--output_exp='expanded_nExPerSent_verbs_randAllExps/01ExPerSent_verbs_rand01_expanded_lu_roles_nouns-50pc'\\\n",
    "--data_dir='data/open_sesame_v1_data/fn1.7'\\\n",
    "--preds_model='bert-large-cased'\\\n",
    "--substitute_lu=True\\\n",
    "--substitute_role=True\\\n",
    "--noun_max=0.5\\\n",
    "--ibn=True\\\n",
    "--match_lugold=True\\\n",
    "--match_rolegold=True\\\n",
    "--proc_funcs='lemma'\\\n",
    "--N=2\\\n",
    "--verbose=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate HTML Tables\n",
    "will save an html table as well as dataframe in csv format\n",
    "- exp_names is optional, if not specified, all experiments from --configs will be executed to produce examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verbs lexical unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m lexsub.run_html_table table \\\n",
    "--base_exp='nExPerSent_verbs_randAllExps/01ExPerSent_verbs_rand01'\\\n",
    "--data_dir='data/open_sesame_v1_data/fn1.7'\\\n",
    "--expanded_exps='{\"BERT\":(\"bert\", (\"nolemma\",True,True), \"nltk_nolemma_role_stopwords_final_predictions.pkl\", \"expanded_nExPerSent_verbs_randAllExps/01ExPerSent_verbs_rand01_expanded_lu_roles_nouns-50pc\"),\"XLNet [+embs]\":(\"xlnet_embs_hypers\", (\"nolemma\",True,True),\"nltk_nolemma_role_stopwords_final_predictions.pkl\",\"expanded_nExPerSent_verbs_randAllExps/01ExPerSent_verbs_rand01_expanded_lu_roles_nouns-50pc\")}'\\\n",
    "--output_file='html_files/expanded_01ExPerSent_verbs_rand01' \\\n",
    "--caption='Examples of expansions for expanded_lu_roles_nouns-50pc, lu and roles were filtered for gold answers.'\\\n",
    "--notations='{}'\\\n",
    "--E=15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nouns lexical unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m lexsub.run_html_table table \\\n",
    "--base_exp='nExPerSent_nouns_randAllExps/01ExPerSent_nouns_rand01'\\\n",
    "--data_dir='data/open_sesame_v1_data/fn1.7'\\\n",
    "--expanded_exps='{\"BERT\":(\"bert\", (\"nolemma\",True,True), \"nltk_nolemma_role_stopwords_final_predictions.pkl\", \"expanded_nExPerSent_nouns_randAllExps/01ExPerSent_nouns_rand01_expanded_lu_roles_nouns-50pc\"),\"XLNet [+embs]\":(\"xlnet_embs_hypers\", (\"nolemma\",True,True),\"nltk_nolemma_role_stopwords_final_predictions.pkl\",\"expanded_nExPerSent_nouns_randAllExps/01ExPerSent_nouns_rand01_expanded_lu_roles_nouns-50pc\")}'\\\n",
    "--output_file='html_files/expanded_01ExPerSent_nouns_rand01' \\\n",
    "--caption='Examples of expansions for expanded_lu_roles_nouns-50pc, lu and roles were filtered for gold answers.'\\\n",
    "--notations='{}'\\\n",
    "--E=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', None)\n",
    "df = pd.read_csv('html_files/expanded_01ExPerSent_verbs_rand01.csv')\n",
    "\n",
    "\n",
    "print(df.to_latex(index=False, escape=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
