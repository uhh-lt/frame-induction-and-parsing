{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sesame.dataio import read_conll\n",
    "from sesame.conll09 import CoNLL09Example, CoNLL09Element\n",
    "from sesame.sentence import Sentence\n",
    "import sys\n",
    "from glob import glob\n",
    "import statistics\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', None)\n",
    "\n",
    "from lexsub.conll_helper import conll_to_sentence, get_frameName, get_luName\n",
    "def get_example_stats(examples):\n",
    "    \n",
    "    examples_per_frame = {}\n",
    "    examples_per_sent = {}\n",
    "    examples_per_lu = {}\n",
    "    frames = set()\n",
    "    sents = set()\n",
    "    lus = set()\n",
    "    \n",
    "    for example in examples:\n",
    "        frame = get_frameName(example)\n",
    "        lu = get_luName(example)\n",
    "        sent = conll_to_sentence(example)\n",
    "        \n",
    "        frames.add(frame)\n",
    "        sents.add(sent)\n",
    "        lus.add(lu)\n",
    "        \n",
    "        if frame in examples_per_frame.keys():\n",
    "            examples_per_frame[frame] += 1\n",
    "        else:\n",
    "            examples_per_frame[frame] = 1\n",
    "            \n",
    "        if sent in examples_per_sent.keys():\n",
    "            examples_per_sent[sent] += 1\n",
    "        else:\n",
    "            examples_per_sent[sent] = 1   \n",
    "            \n",
    "        if lu in examples_per_lu.keys():\n",
    "            examples_per_lu[lu] += 1\n",
    "        else:\n",
    "            examples_per_lu[lu] = 1       \n",
    "    \n",
    "            \n",
    "    return examples_per_sent, examples_per_frame, examples_per_lu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data_dir = 'data/open_sesame_v1_data/fn1.7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "    'original',\n",
    "    'verbs',\n",
    "    'nExPerSent_verbs_randAllExps/01ExPerSent_verbs_rand01',\n",
    "    'nouns',\n",
    "    'nExPerSent_nouns_randAllExps/01ExPerSent_nouns_rand01',\n",
    "\n",
    "]\n",
    "\n",
    "columns=['exp', 'examples', 'sents', 'frames', 'lexical units',\n",
    "         'avg_examples_per_sent', 'avg_examples_per_frame', 'avg_examples_per_lexicalunit',\n",
    "#         'min_examples_per_sent', 'min_examples_per_frame', 'min_examples_per_lexicalunit',\n",
    "        'max_examples_per_sent', 'max_examples_per_frame', 'max_examples_per_lexicalunit']\n",
    "\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for exp in exps:\n",
    "    for model in glob(f'{main_data_dir}/{exp}/*train*.conll'):\n",
    "        try:\n",
    "            examples, __, __ =read_conll(model)\n",
    "            examples_per_sent, examples_per_frame, examples_per_lu = get_example_stats(examples)\n",
    "            \n",
    "        except:\n",
    "            print(model)\n",
    "            continue\n",
    "        \n",
    "        exp_short = exp\n",
    "        df.loc[len(df)] = [exp_short, len(examples), \n",
    "                           len(examples_per_sent), len(examples_per_frame), len(examples_per_lu), \n",
    "                           statistics.mean(examples_per_sent.values()), \n",
    "                           statistics.mean(examples_per_frame.values()),\n",
    "                           statistics.mean(examples_per_lu.values()),\n",
    "#                            min(examples_per_sent.values()), \n",
    "#                            min(examples_per_frame.values()),\n",
    "#                            min(examples_per_lu.values()),\n",
    "                           max(examples_per_sent.values()), \n",
    "                           max(examples_per_frame.values()),\n",
    "                           max(examples_per_lu.values())\n",
    "                          ]\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exps_dir='expanded_nExPerSent_verbs_randAllExps'\n",
    "exps = [\n",
    "'01ExPerSent_verbs_rand01_expanded_lu',\n",
    " '01ExPerSent_verbs_rand01_expanded_roles',\n",
    "'01ExPerSent_verbs_rand01_expanded_nouns-10pc',\n",
    " '01ExPerSent_verbs_rand01_expanded_nouns-30pc',\n",
    " '01ExPerSent_verbs_rand01_expanded_nouns-50pc',\n",
    " '01ExPerSent_verbs_rand01_expanded_lu_roles_nouns-10pc',\n",
    " '01ExPerSent_verbs_rand01_expanded_lu_roles_nouns-30pc',\n",
    " '01ExPerSent_verbs_rand01_expanded_lu_roles_nouns-50pc',\n",
    "]\n",
    "\n",
    "pipeline = 'lugold_rolegold_nltk_nolemma_role_stopwords_N2'\n",
    "pipeline = 'lugold_rolegold_nltk_nolemma_N2'\n",
    "\n",
    "# preds_model = 'xlnet_embs_hypers'\n",
    "preds_model = 'bert'\n",
    "exps = [f'{exps_dir}/{exp}/{preds_model}/{pipeline}' for exp in exps]\n",
    "\n",
    "\n",
    "\n",
    "columns=['exp', 'examples', 'sents', 'frames', 'lexical units',\n",
    "#          'avg_examples_per_sent', \n",
    "         'avg_examples_per_frame', 'avg_examples_per_lexicalunit',\n",
    "#         'min_examples_per_sent', 'min_examples_per_frame', 'min_examples_per_lexicalunit',\n",
    "#         'max_examples_per_sent', 'max_examples_per_frame', 'max_examples_per_lexicalunit'\n",
    "        ]\n",
    "\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for exp in exps:\n",
    "#     print(exp)\n",
    "    for model in glob(f'{main_data_dir}/{exp}/*train*.conll'):\n",
    "        try:\n",
    "            examples, __, __ =read_conll(model)\n",
    "            examples_per_sent, examples_per_frame, examples_per_lu = get_example_stats(examples)\n",
    "            \n",
    "        except:\n",
    "            print(model)\n",
    "            continue\n",
    "        \n",
    "        exp_short = exp.split('/')[1]\n",
    "        df.loc[len(df)] = [exp_short, len(examples), \n",
    "                           len(examples_per_sent), len(examples_per_frame), len(examples_per_lu), \n",
    "#                            statistics.mean(examples_per_sent.values()), \n",
    "                           statistics.mean(examples_per_frame.values()),\n",
    "                           statistics.mean(examples_per_lu.values()),\n",
    "#                            min(examples_per_sent.values()), \n",
    "#                            min(examples_per_frame.values()),\n",
    "#                            min(examples_per_lu.values()),\n",
    "#                            max(examples_per_sent.values()), \n",
    "#                            max(examples_per_frame.values()),\n",
    "#                            max(examples_per_lu.values())\n",
    "                          ]\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exps_dir='expanded_nExPerSent_nouns_randAllExps'\n",
    "exps = [\n",
    "'01ExPerSent_nouns_rand01_expanded_lu',\n",
    " '01ExPerSent_nouns_rand01_expanded_roles',\n",
    "'01ExPerSent_nouns_rand01_expanded_nouns-10pc',\n",
    " '01ExPerSent_nouns_rand01_expanded_nouns-30pc',\n",
    " '01ExPerSent_nouns_rand01_expanded_nouns-50pc',\n",
    " '01ExPerSent_nouns_rand01_expanded_lu_roles_nouns-10pc',\n",
    " '01ExPerSent_nouns_rand01_expanded_lu_roles_nouns-30pc',\n",
    " '01ExPerSent_nouns_rand01_expanded_lu_roles_nouns-50pc',\n",
    "]\n",
    "\n",
    "pipeline = 'lugold_rolegold_nltk_nolemma_role_stopwords_N2'\n",
    "\n",
    "preds_model = 'bert'\n",
    "# preds_model = 'xlnet_embs_hypers'\n",
    "exps = [f'{exps_dir}/{exp}/{preds_model}/{pipeline}' for exp in exps]\n",
    "\n",
    "\n",
    "\n",
    "columns=['exp', 'examples', 'sents', 'frames', 'lexical units',\n",
    "#          'avg_examples_per_sent', \n",
    "         'avg_examples_per_frame', 'avg_examples_per_lexicalunit',\n",
    "#         'min_examples_per_sent', 'min_examples_per_frame', 'min_examples_per_lexicalunit',\n",
    "#         'max_examples_per_sent', 'max_examples_per_frame', 'max_examples_per_lexicalunit'\n",
    "        ]\n",
    "\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for exp in exps:\n",
    "#     print(exp)\n",
    "    for model in glob(f'{main_data_dir}/{exp}/*train*.conll'):\n",
    "        try:\n",
    "            examples, __, __ =read_conll(model)\n",
    "            examples_per_sent, examples_per_frame, examples_per_lu = get_example_stats(examples)\n",
    "            \n",
    "        except:\n",
    "            print(model)\n",
    "            continue\n",
    "        exp_short = exp.split('/')[1]\n",
    "        df.loc[len(df)] = [exp_short, len(examples), \n",
    "                           len(examples_per_sent), len(examples_per_frame), len(examples_per_lu), \n",
    "#                            statistics.mean(examples_per_sent.values()), \n",
    "                           statistics.mean(examples_per_frame.values()),\n",
    "                           statistics.mean(examples_per_lu.values()),\n",
    "#                            min(examples_per_sent.values()), \n",
    "#                            min(examples_per_frame.values()),\n",
    "#                            min(examples_per_lu.values()),\n",
    "#                            max(examples_per_sent.values()), \n",
    "#                            max(examples_per_frame.values()),\n",
    "#                            max(examples_per_lu.values())\n",
    "                          ]\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettify(x):\n",
    "    x = x.split(\"/\")[1]\n",
    "    x = x.replace(\"expanded_nExPerSent_verbs_randAllExps/\", \"\")\n",
    "#     x = x.replace(\"bert/\", \"\")\n",
    "#     x = x.replace(\"xlnet_embs_hypers/\", \"\")\n",
    "#     x = x.replace(\"lugold_rolegold_nltk_nolemma_role_stopwords_N2\", \"\")\n",
    "    x = x.replace(\"01ExPerSent_verbs_rand01_\", \"\")\n",
    "    x = x.replace(\"_\", \"-\")\n",
    "    x = x.replace(\"expanded\", \"augmented\")\n",
    "    x = x.replace(\"lu\", \"lexical unit\")\n",
    "    return x\n",
    "    \n",
    "    \n",
    "df['exp'] = df['exp'].apply(lambda x: prettify(x))\n",
    "df[['exp', 'examples', 'lexical units']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_exps = [\n",
    "    'original',\n",
    "    'verbs',\n",
    "    'nExPerSent_verbs_randAllExps/01ExPerSent_rand01',\n",
    "    'nouns',\n",
    "    'nExPerSent_nouns_randAllExps/01ExPerSent_rand01',\n",
    "]\n",
    "\n",
    "columns=['exp', 'train_frames', 'test_frames', 'dev_frames']\n",
    "\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for exp in base_exps:\n",
    "    frames = [exp]\n",
    "    for model in glob(f'{main_data_dir}/{exp}/*train*.conll'):\n",
    "        try:\n",
    "            examples, __, __ =read_conll(model)\n",
    "            examples_per_sent, examples_per_frame, examples_per_lu = get_example_stats(examples)\n",
    "            frames.append(list(examples_per_frame.keys()))\n",
    "        except:\n",
    "            print(model)\n",
    "            continue\n",
    "    for model in glob(f'{main_data_dir}/{exp}/*test*.conll'):\n",
    "        try:\n",
    "            examples, __, __ =read_conll(model)\n",
    "            examples_per_sent, examples_per_frame, examples_per_lu = get_example_stats(examples)\n",
    "            frames.append(list(examples_per_frame.keys()))\n",
    "        except:\n",
    "            print(model)\n",
    "            continue \n",
    "    for model in glob(f'{main_data_dir}/{exp}/*dev*.conll'):\n",
    "        try:\n",
    "            examples, __, __ =read_conll(model)\n",
    "            examples_per_sent, examples_per_frame, examples_per_lu = get_example_stats(examples)\n",
    "            frames.append(list(examples_per_frame.keys()))\n",
    "        except:\n",
    "            print(model)\n",
    "            continue   \n",
    "        df.loc[len(df)] = frames\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['test_not_in_train'] = df.apply(lambda row: len(set(row['test_frames']) - set(row['train_frames'])), axis=1)\n",
    "df['test_frames_n'] = df['test_frames'].apply(lambda row: len(row))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\n",
    "#     'original',\n",
    "    'verbs',\n",
    "]\n",
    "columns=['exp', 'examples', 'sents', 'frames', 'lus', 'avg_examples_per_sent', 'avg_examples_per_frame', 'avg_examples_per_lu']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for exp in exps:\n",
    "    for model in glob(f'{main_data_dir}/{exp}/*test*.conll'):\n",
    "        try:\n",
    "            examples, __, __ =read_conll(model)\n",
    "            examples_per_sent2, examples_per_frame2, examples_per_lu2 = get_example_stats(examples)\n",
    "            \n",
    "        except:\n",
    "            print(model)\n",
    "            continue\n",
    "        \n",
    "        df.loc[len(df)] = [exp, len(examples), \n",
    "                           len(examples_per_sent2), len(examples_per_frame2), len(examples_per_lu2), \n",
    "                           statistics.mean(examples_per_sent2.values()), \n",
    "                           statistics.mean(examples_per_frame2.values()),\n",
    "                           statistics.mean(examples_per_lu2.values())\n",
    "                          ]\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exps_dir = \"nPc_verbs_randAllExps\"\n",
    "exps = [\n",
    "    '010pc_verbs',\n",
    "    '020pc_verbs',\n",
    "    '030pc_verbs',\n",
    "    '040pc_verbs',\n",
    "    '050pc_verbs',\n",
    "    '100pc_verbs'\n",
    "]\n",
    "\n",
    "exps = [f\"{exps_dir}/{exp}\" for exp in exps]\n",
    "\n",
    "columns=['exp', 'examples', 'sents', 'frames', 'lus', 'avg_examples_per_sent', 'avg_examples_per_frame', 'avg_examples_per_lu']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for exp in exps:\n",
    "    for model in glob(f'{main_data_dir}/{exp}/*train*.conll'):\n",
    "        try:\n",
    "            examples, __, __ =read_conll(model)\n",
    "            examples_per_sent, examples_per_frame, examples_per_lu = get_example_stats(examples)\n",
    "            \n",
    "        except:\n",
    "            print(model)\n",
    "            continue\n",
    "        \n",
    "        df.loc[len(df)] = [exp, len(examples), \n",
    "                           len(examples_per_sent), len(examples_per_frame), len(examples_per_lu), \n",
    "                           statistics.mean(examples_per_sent.values()), \n",
    "                           statistics.mean(examples_per_frame.values()),\n",
    "                           statistics.mean(examples_per_lu.values())\n",
    "                          ]\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_dir = \"nPc_nouns_randAllExps\"\n",
    "exps = [\n",
    "    '010pc_nouns',\n",
    "    '020pc_nouns',\n",
    "    '030pc_nouns',\n",
    "    '040pc_nouns',\n",
    "    '050pc_nouns',\n",
    "    '100pc_nouns'\n",
    "]\n",
    "\n",
    "exps = [f\"{exps_dir}/{exp}\" for exp in exps]\n",
    "\n",
    "columns=['exp', 'examples', 'sents', 'frames', 'lus', 'avg_examples_per_sent', 'avg_examples_per_frame', 'avg_examples_per_lu']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for exp in exps:\n",
    "    for model in glob(f'{main_data_dir}/{exp}/*train*.conll'):\n",
    "        try:\n",
    "            examples, __, __ =read_conll(model)\n",
    "            examples_per_sent, examples_per_frame, examples_per_lu = get_example_stats(examples)\n",
    "            \n",
    "        except:\n",
    "            print(model)\n",
    "            continue\n",
    "        \n",
    "        df.loc[len(df)] = [exp, len(examples), \n",
    "                           len(examples_per_sent), len(examples_per_frame), len(examples_per_lu), \n",
    "                           statistics.mean(examples_per_sent.values()), \n",
    "                           statistics.mean(examples_per_frame.values()),\n",
    "                           statistics.mean(examples_per_lu.values())\n",
    "                          ]\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['exp', 'examples']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
